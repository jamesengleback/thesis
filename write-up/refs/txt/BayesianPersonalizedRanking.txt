452

RENDLE ET AL.

UAI 2009

BPR: Bayesian Personalized Ranking from Implicit Feedback

Steﬀen Rendle, Christoph Freudenthaler, Zeno Gantner and Lars Schmidt-Thieme

{srendle, freudenthaler, gantner, schmidt-thieme}@ismll.de

Machine Learning Lab, University of Hildesheim

Marienburger Platz 22, 31141 Hildesheim, Germany

Abstract

Item recommendation is the task of predict-
ing a personalized ranking on a set of items
(e.g. websites, movies, products).
In this
paper, we investigate the most common sce-
nario with implicit feedback (e.g.
clicks,
purchases). There are many methods for
item recommendation from implicit feedback
like matrix factorization (MF) or adaptive k-
nearest-neighbor (kNN). Even though these
methods are designed for the item predic-
tion task of personalized ranking, none of
them is directly optimized for ranking.
In
this paper we present a generic optimization
criterion BPR-Opt for personalized ranking
that is the maximum posterior estimator de-
rived from a Bayesian analysis of the prob-
lem. We also provide a generic learning al-
gorithm for optimizing models with respect
to BPR-Opt. The learning method is based
on stochastic gradient descent with bootstrap
sampling. We show how to apply our method
to two state-of-the-art recommender models:
matrix factorization and adaptive kNN. Our
experiments indicate that for the task of per-
sonalized ranking our optimization method
outperforms the standard learning techniques
for MF and kNN. The results show the im-
portance of optimizing models for the right
criterion.

1

Introduction

Recommending content is an important task in many
information systems. For example online shopping
websites like Amazon give each customer personalized
recommendations of products that the user might be
interested in. Other examples are video portals like
YouTube that recommend movies to customers. Per-

sonalization is attractive both for content providers,
who can increase sales or views, and for customers,
who can ﬁnd interesting content more easily. In this
paper, we focus on item recommendation. The task of
item recommendation is to create a user-speciﬁc rank-
ing for a set of items. Preferences of users about items
are learned from the user’s past interaction with the
system – e.g. his buying history, viewing history, etc.
Recommender systems are an active topic of research.
Most recent work is on scenarios where users provide
explicit feedback, e.g.
in terms of ratings. Never-
theless, in real-world scenarios most feedback is not
explicit but implicit. Implicit feedback is tracked au-
tomatically, like monitoring clicks, view times, pur-
chases, etc. Thus it is much easier to collect, because
the user has not to express his taste explicitly. In fact
implicit feedback is already available in almost any in-
formation system – e.g. web servers record any page
access in log ﬁles.
In this paper we present a generic method for learning
models for personalized ranking. The contributions of
this work are:

1. We present the generic optimization criterion
BPR-Opt derived from the maximum posterior
estimator for optimal personalized ranking. We
show the analogies of BPR-Opt to maximization
of the area under ROC curve.

2. For maximizing BPR-Opt, we propose the
generic learning algorithm LearnBPR that is
based on stochastic gradient descent with boot-
strap sampling of training triples. We show that
our algorithm is superior to standard gradient de-
scent techniques for optimizing w.r.t. BPR-Opt.
3. We show how to apply LearnBPR to two state-

of-the-art recommender model classes.

4. Our experiments empirically show that for the
task of of personalized ranking, learning a model
with BPR outperforms other learning methods.

UAI 2009

RENDLE ET AL.

453

2 Related Work

The most popular model for recommender systems is
k-nearest neighbor (kNN) collaborative ﬁltering [2].
Traditionally the similarity matrix of kNN is com-
puted by heuristics – e.g. the Pearson correlation –
but in recent work [8] the similarity matrix is treated
as model parameters and is learned speciﬁcally for the
task. Recently, matrix factorization (MF) has become
very popular in recommender systems both for im-
plicit and explicit feedback.
In early work [13] sin-
gular value decomposition (SVD) has been proposed
to learn the feature matrices. MF models learned by
SVD have shown to be very prone to overﬁtting. Thus
regularized learning methods have been proposed. For
item prediction Hu et al. [5] and Pan et al. [10] pro-
pose a regularized least-square optimization with case
weights (WR-MF). The case weights can be used to
reduce the impact of negative examples. Hofmann [4]
proposes a probabilistic latent semantic model for item
recommendation. Schmidt-Thieme [14] converts the
problem into a multi-class problem and solves it with
a set of binary classiﬁers. Even though all the work on
item prediction discussed above is evaluated on per-
sonalized ranking datasets, none of these methods di-
rectly optimizes its model parameters for ranking. In-
stead they optimize to predict if an item is selected
by a user or not. In our work we derive an optimiza-
tion criterion for personalized ranking that is based
on pairs of items (i.e. the user-speciﬁc order of two
items). We will show how state-of-the-art models like
MF or adaptive kNN can be optimized with respect to
this criterion to provide better ranking quality than
with usual learning methods. A detailed discussion of
the relationship between our approach and the WR-
MF approach of Hu et al.
[10] as
well as maximum margin matrix factorization [15] can
be found in Section 5. In Section 4.1.1, we will also
discuss the relations of our optimization criterion to
AUC optimization like in [3].
In this paper, we focus on oﬄine learning of the model
parameters. Extending the learning method to online
learning scenarios – e.g. a new user is added and his
history increases from 0 to 1, 2, . . . feedback events –
has already been studied for MF for the related task of
rating prediction [11]. The same fold-in strategy can
be used for BPR.
There is also related work on learning to rank with
non-collaborative models. One direction is to model
distributions on permutations [7, 6]. Burges et al. [1]
optimize a neural network model for ranking using gra-
dient descent. All these approaches learn only one
ranking – i.e. they are non-personalized. In contrast
to this, our models are collaborative models that learn

[5] and Pan et al.

personalized rankings, i.e. one individual ranking per
user. In our evaluation, we show empirically that in
typical recommender settings our personalized BPR
model outperforms even the theoretical upper bound
for non-personalized ranking.

3 Personalized Ranking

The task of personalized ranking is to provide a user
with a ranked list of items. This is also called item
recommendation. An example is an online shop that
wants to recommend a personalized ranked list of items
that the user might want to buy.
In this paper we
investigate scenarios where the ranking has to be in-
ferred from the implicit behavior (e.g. purchases in the
past) of the user. Interesting about implicit feedback
systems is that only positive observations are avail-
able. The non-observed user-item pairs – e.g. a user
has not bought an item yet – are a mixture of real
negative feedback (the user is not interested in buying
the item) and missing values (the user might want to
buy the item in the future).

3.1 Formalization

Let U be the set of all users and I the set of all items.
In our scenario implicit feedback S ⊆ U ×I is available
(see left side of Figure 1). Examples for such feedback
are purchases in an online shop, views in a video portal
or clicks on a website. The task of the recommender
system is now to provide the user with a personalized
total ranking >u⊂ I 2 of all items, where >u has to
meet the properties of a total order:
∀i, j ∈ I : i (cid:54)= j ⇒ i >u j ∨ j >u i
∀i, j ∈ I : i >u j ∧ j >u i ⇒ i = j
∀i, j, k ∈ I : i >u j ∧ j >u k ⇒ i >u k
For convenience we also deﬁne:

(totality)
(antisymmetry)
(transitivity)

u := {i ∈ I : (u, i) ∈ S}
I +
:= {u ∈ U : (u, i) ∈ S}
U +
i

3.2 Analysis of the problem setting

As we have indicated before, in implicit feedback sys-
tems only positive classes are observed. The remain-
ing data is a mixture of actually negative and missing
values. The most common approach for coping with
the missing value problem is to ignore all of them but
then typical machine learning models are unable to
learn anything, because they cannot distinguish be-
tween the two levels anymore.
The usual approach for item recommenders is to pre-
dict a personalized score ˆxui for an item that reﬂects

454

RENDLE ET AL.

UAI 2009

Figure 1: On the left side, the observed data S is
shown. Learning directly from S is not feasible as only
positive feedback is observed. Usually negative data is
generated by ﬁlling the matrix with 0 values.

the preference of the user for the item. Then the items
are ranked by sorting them according to that score.
Machine learning approaches for item recommenders
[5, 10] typically create the training data from S by
giving pairs (u, i) ∈ S a positive class label and all
other combinations in (U × I) \ S a negative one (see
Figure 1). Then a model is ﬁtted to this data. That
means the model is optimized to predict the value 1 for
elements in S and 0 for the rest. The problem with this
approach is that all elements the model should rank in
the future ((U × I) \ S) are presented to the learning
algorithm as negative feedback during training. That
means a model with enough expressiveness (that can
ﬁt the training data exactly) cannot rank at all as it
predicts only 0s. The only reason why such machine
learning methods can predict rankings are strategies
to prevent overﬁtting, like regularization.
We use a diﬀerent approach by using item pairs as
training data and optimize for correctly ranking item
pairs instead of scoring single items as this better rep-
resents the problem than just replacing missing values
with negative ones. From S we try to reconstruct for
each user parts of >u. If an item i has been viewed
(u, i) ∈ S – then we assume that
by user u – i.e.
the user prefers this item over all other non-observed
items. E.g. in Figure 2 user u1 has viewed item i2 but
not item i1, so we assume that this user prefers item
i2 over i1: i2 >u i1. For items that have both been
seen by a user, we cannot infer any preference. The
same is true for two items that a user has not seen yet
(e.g. item i1 and i4 for user u1). To formalize this we
create training data DS : U × I × I by:

DS := {(u, i, j)|i ∈ I +

u ∧ j ∈ I \ I +
u }

The semantics of (u, i, j) ∈ DS is that user u is as-
sumed to prefer i over j. As >u is antisymmetric, the
negative cases are regarded implicitly.
Our approach has two advantages:

1. Our training data consists of both positive and

Figure 2: On the left side, the observed data S is
shown. Our approach creates user speciﬁc pairwise
preferences i >u j between a pair of items. On the
right side, plus (+) indicates that a user prefers item i
over item j; minus (–) indicates that he prefers j over i.

negative pairs and missing values. The missing
values between two non-observed items are ex-
actly the item pairs that have to be ranked in
the future. That means from a pairwise point of
view the training data DS and the test data is
disjoint.

2. The training data is created for the actual objec-
tive of ranking, i.e. the observed subset DS of >u
is used as training data.

4 Bayesian Personalized Ranking

(BPR)

In this section we derive a generic method for solv-
ing the personalized ranking task. It consists of the
general optimization criterion for personalized rank-
ing, BPR-Opt, which will be derived by a Bayesian
analysis of the problem using the likelihood function
for p(i >u j|Θ) and the prior probability for the model
parameter p(Θ). We show the analogies to the ranking
statistic AUC (area under the ROC curve). For learn-
ing models with respect to BPR-Opt, we propose the
algorithm LearnBPR. Finally, we show how BPR-
Opt and LearnBPR can be applied to two state-of-
the-art recommender algorithms, matrix factorization
and adaptive kNN. Optimized with BPR these mod-
els are able to generate better rankings than with the
usual training methods.

?++?+??+++????++??+?i1   i2    i3   i4itemuseru1u2u3u4u501101001110000110010i1   i2    i3   i4itemuseru1u2u3u4u5?++?+??+++????++??+?i1   i2    i3   i4itemuseru1u2u3u4u5++?­?­­?­?++i1   i2    i3   i4j1j2j3j4itemitemu1:   i >u1 j?+??+?­­­??+i1   i2    i3   i4j1j2j3j4itemitemu5:   i >u5 j...UAI 2009

RENDLE ET AL.

455

4.1 BPR Optimization Criterion

The Bayesian formulation of ﬁnding the correct per-
sonalized ranking for all items i ∈ I is to maximize
the following posterior probability where Θ represents
the parameter vector of an arbitrary model class (e.g.
matrix factorization).

p(Θ| >u) ∝ p(>u |Θ) p(Θ)

Here, >u is the desired but latent preference structure
for user u. All users are presumed to act independently
of each other. We also assume the ordering of each
pair of items (i, j) for a speciﬁc user is independent
of the ordering of every other pair. Hence, the above
user-speciﬁc likelihood function p(>u |Θ) can ﬁrst be
rewritten as a product of single densities and second
be combined for all users u ∈ U.

p(>u |Θ) = (cid:89)

(cid:89)

u∈U

(u,i,j)∈U×I×I

p(i >u j|Θ)δ((u,i,j)∈DS )

· (1 − p(i >u j|Θ))δ((u,j,i)(cid:54)∈DS )

where δ is the indicator function:

(cid:40)

δ(b) :=

1 if b is true,
0 else

Due to the totality and antisymmetry of a sound pair-
wise ordering scheme the above formula can be simpli-

ﬁed to: (cid:89)

p(>u |Θ) = (cid:89)

u∈U

(u,i,j)∈DS

p(i >u j|Θ)

So far it is generally not guaranteed to get a person-
alized total order. In order to establish this, the al-
ready mentioned sound properties (totality, antisym-
metry and transitivity) need to be fulﬁlled. To do so,
we deﬁne the individual probability that a user really
prefers item i to item j as:

p(i >u j|Θ) := σ(ˆxuij(Θ))

where σ is the logistic sigmoid:

σ(x) :=

1

1 + e−x

Figure 3: Loss functions for optimizing the AUC.
The non-diﬀerentiable Heaviside H(x) is often approx-
imated by the sigmoid σ(x). Our MLE derivation sug-
gests to use ln σ(x) instead.

model a personalized total order >u. For convenience,
in the following we will skip the argument Θ from ˆxuij.
So far, we have only discussed the likelihood function.
In order to complete the Bayesian modeling approach
of the personalized ranking task, we introduce a gen-
eral prior density p(Θ) which is a normal distribution
with zero mean and variance-covariance matrix ΣΘ.

p(Θ) ∼ N(0, ΣΘ)

In the following, to reduce the number of unknown
hyperparameters we set ΣΘ = λΘI. Now we can for-
mulate the maximum posterior estimator to derive our
generic optimization criterion for personalized ranking
BPR-Opt.

BPR-Opt := ln p(Θ| >u)

= ln p(>u |Θ) p(Θ)

(u,i,j)∈DS

= ln (cid:89)
= (cid:88)
= (cid:88)

(u,i,j)∈DS

(u,i,j)∈DS

σ(ˆxuij) p(Θ)

ln σ(ˆxuij) + ln p(Θ)

ln σ(ˆxuij) − λΘ||Θ||2

Here ˆxuij(Θ) is an arbitrary real-valued function of
the model parameter vector Θ which captures the spe-
cial relationship between user u, item i and item j.
In other words, our generic framework delegates the
task of modeling the relationship between u, i and j
to an underlying model class like matrix factorization
or adaptive kNN, which are in charge of estimating
ˆxuij(Θ). Hence, it becomes feasible to statistically

where λΘ are model speciﬁc regularization parameters.

4.1.1 Analogies to AUC optimization

With this formulation of the Bayesian Personalized
Ranking (BPR) scheme, it is now easy to grasp the
analogy between BPR and AUC. The AUC per user is

−6−4−20246−1.5−0.50.51.0Loss functionsxf(x)HeavisideHingeSigmoidln Sigmoid456

RENDLE ET AL.

UAI 2009

usually deﬁned as:

AUC(u) :=

1

|I +
u ||I \ I +
u |

(cid:88)

(cid:88)

i∈I+

u

j∈|I\I+
u |

δ(ˆxuij > 0)

Hence the average AUC is:

AUC :=

1
|U|

(cid:88)

u∈U

AU C(u)

With our notation of DS this can be written as:

AUC(u) = (cid:88)

(u,i,j)∈DS

zu δ(ˆxuij > 0)

(1)

where zu is the normalizing constant:

zu =

1
u ||I \ I +
u |

|U||I +

The analogy between (1) and BPR-Opt is obvious.
Besides the normalizing constant zu they only diﬀer in
the loss function. The AUC uses the non-diﬀerentiable
loss δ(x > 0) which is identical to the Heaviside func-
tion:

(cid:40)

1, x > 0
0,

else

δ(x > 0) = H(x) :=

Instead we use the diﬀerentiable loss ln σ(x). It is com-
mon practice to replace the non-diﬀerentiable Heav-
iside function when optimizing for AUC [3]. Often
the choice of the substitution is heuristic and a simi-
larly shaped function like σ is used (see ﬁgure 3). In
this paper, we have derived the alternative substitu-
tion ln σ(x) that is motivated by the MLE.

4.2 BPR Learning Algorithm

In the last section we have derived an optimization
criterion for personalized ranking. As the criterion
is diﬀerentiable, gradient descent based algorithms
are an obvious choice for maximization. But as we
will see, standard gradient descent is not the right
choice for our problem. To solve this issue we propose
LearnBPR, a stochastic gradient-descent algorithm
based on bootstrap sampling of training triples (see
ﬁgure 4).
First of all the gradient of BPR-Opt with respect to
the model parameters is:

= (cid:88)
∝ (cid:88)

(u,i,j)∈DS

(u,i,j)∈DS

∂
∂Θ
−e−ˆxuij
1 + e−ˆxuij

ln σ(ˆxuij) − λΘ

||Θ||2

∂
∂Θ

· ∂
∂Θ

ˆxuij − λΘΘ

∂BPR-Opt

∂Θ

1: procedure LearnBPR(DS, Θ)
2:
3:
4:

initialize Θ
repeat

draw (u, i, j) from DS
Θ ← Θ + α

(cid:16) e

−ˆxuij · ∂
−ˆxuij

5:

1+e

(cid:17)
∂Θ ˆxuij + λΘ · Θ

until convergence
return ˆΘ

6:
7:
8: end procedure

Figure 4: Optimizing models for BPR with bootstrap-
ping based stochastic gradient descent. With learning
rate α and regularization λΘ.

The two most common algorithms for gradient descent
are either full or stochastic gradient descent. In the
ﬁrst case, in each step the full gradient over all training
data is computed and then the model parameters are
updated with the learning rate α:

Θ ← Θ − α

∂BPR-Opt

∂Θ

In general this approach leads to a descent in the ‘cor-
rect’ direction, but convergence is slow. As we have
O(|S||I|) training triples in DS, computing the full
gradient in each update step is not feasible. Further-
more, for optimizing BPR-Opt with full gradient de-
scent also the skewness in the training pairs leads to
poor convergence. Imagine an item i that is often pos-
itive. Then we have many terms of the form ˆxuij in the
loss because for many users u the item i is compared
against all negative items j (the dominating class).
Thus the gradient for model parameters depending on
i would dominate largely the gradient. That means
very small learning rates would have to be chosen. Sec-
ondly, regularization is diﬃcult as the gradients diﬀer
much.
The other popular approach is stochastic gradient de-
In this case for each triple (u, i, j) ∈ DS an
scent.
update is performed.

(cid:18) e−ˆxuij

1 + e−ˆxuij

Θ ← Θ + α

· ∂
∂Θ

ˆxuij + λΘΘ

(cid:19)

In general this is a good approach for our skew problem
but the order in which the training pairs are traversed
is crucial. A typical approach that traverses the data
item-wise or user-wise will lead to poor convergence
as there are so many consecutive updates on the same
user-item pair – i.e. for one user-item pair (u, i) there
are many j with (u, i, j) ∈ DS.
To solve this issue we suggest to use a stochastic gra-
dient descent algorithm that chooses the triples ran-
domly (uniformly distributed). With this approach
the chances to pick the same user-item combination

UAI 2009

RENDLE ET AL.

457

Now we can apply any standard collaborative ﬁltering
model that predicts ˆxul.
It is important to note that even though we use the
same models as in other work, we optimize them
against another criterion. This will lead to a better
ranking because our criterion is optimal for the rank-
ing task. Our criterion does not try to regress a single
predictor ˆxul to a single number but instead tries to
classify the diﬀerence of two predictions ˆxui − ˆxuj.

4.3.1 Matrix Factorization

The problem of predicting ˆxui can be seen as the task
of estimating a matrix X : U × I. With matrix fac-
torization the target matrix X is approximated by the
matrix product of two low-rank matrices W : |U| × k
and H : |I| × k:

ˆX := W H t

where k is the dimensionality/rank of the approxima-
tion. Each row wu in W can be seen as a feature vector
describing a user u and similarly each row hi of H de-
scribes an item i. Thus the prediction formula can also
be written as:

ˆxui = (cid:104)wu, hi(cid:105) =

wuf · hif

k(cid:88)

f =1

Besides the dot product (cid:104)·,·(cid:105) in general any kernel can
be used like in [11]. The model parameters for matrix
factorization are Θ = (W, H). The model parameters
can also be seen as latent variables, modeling the non-
observed taste of a user and the non-observed proper-
ties of an item.
In general the best approximation of ˆX to X with re-
spect to least-square is achieved by the singular value
decomposition (SVD). For machine learning tasks, it is
known that SVD overﬁts and therefore many other ma-
trix factorization methods have been proposed, includ-
ing regularized least square optimization, non-negative
factorization, maximum margin factorization, etc.
For the task of ranking,
estimating whether
a user prefers one item over another, a better ap-
proach is to optimize against the BPR-Opt crite-
rion. This can be achieved by using our proposed al-
gorithm LearnBPR. As stated before for optimizing
with LearnBPR, only the gradient of ˆxuij with re-
spect to every model parameter θ has to be known.
For the matrix factorization model the derivatives are:

i.e.



∂
∂θ

ˆxuij =

(hif − hjf )
wuf
−wuf
0

if θ = wuf ,
if θ = hif ,
if θ = hjf ,
else

Figure 5: Empirical comparison of the convergence
of typical user-wise stochastic gradient descent to our
LearnBPR algorithm with bootstrap sampling.

in consecutive update steps is small. We suggest to
use a bootstrap sampling approach with replacement
because stopping can be performed at any step. Aban-
doning the idea of full cycles through the data is es-
pecially useful in our case as the number of examples
is very large and for convergence often a fraction of a
full cycle is suﬃcient. We choose the number of sin-
gle steps in our evaluation linearly depending on the
number of observed positive feedback S.
Figure 5 shows a comparison1 of a typical user-
wise stochastic gradient descent to our approach
LearnBPR with bootstrapping. The model is BPR-
MF with 16 dimensions. As you can see LearnBPR
converges much faster than user-wise gradient descent.

4.3 Learning models with BPR

In the following we describe two state-of-the-art model
classes for item recommendation and how we can learn
them with our proposed BPR methods. We have cho-
sen the two diverse model classes of matrix factoriza-
tion [5, 12] and learned k-nearest-neighbor [8]. Both
classes try to model the hidden preferences of a user
on an item. Their prediction is a real number ˆxul per
user-item-pair (u, l).
Because in our optimization we have triples (u, i, j) ∈
DS, we ﬁrst decompose the estimator ˆxuij and deﬁne
it as:

ˆxuij := ˆxui − ˆxuj

1Details about the dataset and evaluation method can

be found in Section 6.

0e+002e+094e+096e+090.50.60.70.80.91.0Convergence on Rossmann datasetNumber of single updatesAUCLearnBPRuser−wise stochastic gradient descent458

RENDLE ET AL.

UAI 2009

Furthermore, we use three regularization constants:
one λW for the user features W ; for the item features
H we have two regularization constants, λH+ that is
used for positive updates on hif , and λH− for negative
updates on hjf .

4.3.2 Adaptive k-Nearest-Neighbor

5 Relations to other methods

We discuss the relations of our proposed methods for
ranking to two further item prediction models.

5.1 Weighted Regularized Matrix

Factorization (WR-MF)

Nearest-neighbor methods are very popular in collab-
orative ﬁltering. They rely on a similarity measure be-
tween either items (item-based) or users (user-based).
In the following we describe item-based methods as
they usually provide better results, but user-based
methods work analogously. The idea is that the pre-
diction for a user u and an item i depends on the
similarity of i to all other items the user has seen in
the past – i.e. I +
u . Often only the k most similar items
u are regarded – the k-nearest neighbors. If the
of I +
similarities between items are chosen carefully, one can
u . For item prediction
also compare to all items in I +
the model of item-based k-nearest-neighbor is:

ˆxui = (cid:88)

cil

l∈I+

u ∧l(cid:54)=i

where C : I × I is the symmetric item-correlation/
item-similarity matrix. Hence the model parameters
of kNN are Θ = C.
The common approach for choosing C is by applying
a heuristic similarity measure, e.g. cosine vector simi-
larity:

ccosine
i,j

:=

(cid:113)|U +

i ∩ U +
|U +
j |
i | · |U +
j |

A better strategy is to adapt the similarity measure C
to the problem by learning it. This can be either done
by using C directly as model parameters or if the num-
ber of items is too large, one can learn a factorization
HH t of C with H : I × k. In the following and also in
our evaluation we use the ﬁrst approach of learning C
directly without factorizing it.
Again for optimizing the kNN model for ranking, we
apply the BPR optimization criterion and use the
LearnBPR algorithm. For applying the algorithm,
the gradient of ˆxuij with respect to the model param-
eters C is:

+1

−1
0

∂
∂θ

ˆxuij =

if θ ∈ {cil, cli} ∧ l ∈ I +
if θ ∈ {cjl, clj} ∧ l ∈ I +
else

u ∧ l (cid:54)= i,
u ∧ l (cid:54)= j,

We have two regularization constants, λ+ for updates
on cil, and λ− for updates on cjl.

Both Pan et al. [10] and Hu et al. [5] have presented a
matrix factorization method for item prediction from
implicit feedback. Thus the model class is the same as
we described in Section 4.3.1, i.e. ˆX := W H t with the
matrices W : |U| × k and H : |U| × k. The optimiza-
tion criterion and learning method diﬀer substantially
from our approach. Their method is an adaption of
a SVD, which minimizes the square-loss. Their ex-
tensions are regularization to prevent overﬁtting and
weights in the error function to increase the impact of
positive feedback. In total their optimization criterion

cui((cid:104)wu, hi(cid:105) − 1)2 + λ||W||2

f + λ||H||2

f

is: (cid:88)

(cid:88)

u∈U

i∈I

where cui are not model parameters but apriori given
weights for each tuple (u, i). Hu et al. have additional
data to estimate cui for positive feedback and they set
cui = 1 for the rest. Pan et al. suggest to set cui = 1
for positive feedback and choose lower constants for
the rest.
First of all, it is obvious that this optimization is on in-
stance level (one item) instead of pair level (two items)
as BPR. Apart from this, their optimization is a least-
square which is known to correspond to the MLE for
normally distributed random variables. However, the
task of item prediction is actually not a regression
(quantitative), but a classiﬁcation (qualitative) one,
so the logistic optimization is more appropriate.
A strong point of WR-MF is that it can be learned in
O(iter (|S| k2 + k3 (|I|+|U|))) provided that cui is con-
stant for non-positive pairs. Our evaluation indicates
that LearnBPR usually converges after a subsample
of m · |S| single update steps even though there are
much more triples to learn from.

5.2 Maximum Margin Matrix Factorization

(MMMF)

Weimer et al.
[15] use the maximum margin ma-
trix factorization method (MMMF) for ordinal rank-
ing. Their MMMF is designed for scenarios with ex-
plicit feedback in terms of ratings. Even though their
ranking MMMF is not intended for implicit feedback
datasets, one could apply it in our scenario by giving
all non-observed items the ‘rating’ 0 and the observed
ones a 1 (see Figure 1). With these modiﬁcations their

UAI 2009

RENDLE ET AL.

459

optimization criterion to be minimized would be quite
similar to BPR applied for matrix factorization:

max(0, 1−(cid:104)wu, hi − hj(cid:105))+λw||W||2

f +λh||H||2

f

(cid:88)

(u,i,j)∈Ds

One diﬀerence is that the error functions diﬀer – our
hinge loss is smooth and motivated by the MLE. Ad-
ditionally, our BPR-Opt criterion is generic and can
be applied to several models, whereas their method is
speciﬁc for MF.
Besides this, their learning method for MMMF diﬀers
from our generic approach LearnBPR. Their learning
method is designed to work with sparse explicit data,
i.e. they assume that there are many missing values
and thus they assume to have much less pairs than in
an implicit setting. But when their learning method
is applied to implicit feedback datasets, the data has
to be densiﬁed like described above and the number
of training pairs DS is in O(|S||I|). Our method
LearnBPR can handle this situation by bootstrap-
ping from DS (see Section 4.2).

6 Evaluation

In our evaluation we compare learning with BPR to
other learning approaches. We have chosen the two
popular model classes of matrix factorization (MF)
and k-nearest-neighbor (kNN). MF models are known
to outperform [12] many other models including the
Bayesian models URP [9] and PLSA [4] for the related
task of collaborative rating prediction.
In our eval-
uation, the matrix factorization models are learned
by three diﬀerent methods, i.e. SVD-MF, WR-MF
[5, 10] and our BPR-MF. For kNN, we compare cosine
vector similarity (Cosine-kNN) to a model that has
been optimized using our BPR method (BPR-kNN).
Additionally, we report results for the baseline most-
popular, that weights each item user-independent, e.g.:
i |. Furthermore, we give the theo-
ˆxmost-pop
ui
retical upper bound on AUC (npmax) for any non-
personalized ranking method.

:= |U +

6.1 Datasets

We use two datasets of two diﬀerent applications. The
Rossmann dataset is from an online shop. It contains
the buying history of 10, 000 users on 4000 items. In
total 426, 612 purchases are recorded. The task is to
predict a personalized list of the items the user wants
to buy next. The second dataset is the DVD rental
dataset of Netﬂix. This dataset contains the rating
behavior of users, where a user provides explicit ratings
1 to 5 stars for some movies. As we want to solve an
implicit feedback task, we removed the rating scores

from the dataset. Now the task is to predict if a user
is likely to rate a movie. Again we are interested in a
personalized ranked list starting with the movie that
is most likely to be rated. For Netﬂix we have created
a subsample of 10, 000 users, 5000 items containing
565, 738 rating actions. We draw the subsample such
that every user has at least 10 items (∀u ∈ U : |I +
u | ≥
10) and each item has at least 10 users: ∀i ∈ I : |U +
i | ≥
10.

6.2 Evaluation Methodology

We use the leave one out evaluation scheme, where we
remove for each user randomly one action (one user-
item pair) from his history, i.e. we remove one entry
from I +
u per user u. This results in a disjoint train set
Strain and test set Stest. The models are then learned
on Strain and their predicted personalized ranking is
evaluated on the test set Stest by the average AUC
statistic:

(cid:88)

u

(cid:88)

(i,j)∈E(u)

AUC =

1
|U|

1

|E(u)|

δ(ˆxui > ˆxuj)

(2)

where the evaluation pairs per user u are:
E(u) := {(i, j)|(u, i) ∈ Stest ∧ (u, j) (cid:54)∈ (Stest ∪ Strain)}
A higher value of the AUC indicates a better quality.
The trivial AUC of a random guess method is 0.5 and
the best achievable quality is 1.
We repeated all experiments 10 times by drawing new
train/test splits in each round. The hyperparameters
for all methods are optimized via grid search in the
ﬁrst round and afterwards are kept constant in the
remaining 9 repetitions.

6.3 Results and Discussion

Figure 6 shows the AUC quality of all models on the
two datasets. First of all, you can see that the two
BPR optimized methods outperform all other meth-
ods in prediction quality. Comparing the same mod-
els among each other one can see the importance of
the optimization method. For example all MF meth-
ods (SVD-MF, WR-MF and BPR-MF) share exactly
the same model, but their prediction quality diﬀers a
lot. Even though SVD-MF is known to yield the best
ﬁt on the training data with respect to element-wise
least square, it is a poor prediction method for machine
learning tasks as it results in overﬁtting. This can be
seen as the quality of SVD-MF decreases with an in-
creasing number of dimensions. WR-MF is a more
successful learning method for the task of ranking.
Due to regularization its performance does not drop
but steadily rises with an increasing number of dimen-
sions. But BPR-MF outperforms WR-MF clearly for

460

RENDLE ET AL.

UAI 2009

Figure 6: Area under the ROC curve (AUC) prediction quality for the Rossmann dataset and a Netﬂix subsample.
Our BPR optimizations for matrix factorization BPR-MF and k-nearest neighbor BPR-kNN are compared
against weighted regularized matrix factorization (WR-MF) [5, 10], singular value decomposition (SVD-MF),
k-nearest neighbor (Cosine-kNN) [2] and the most-popular model. For the factorization methods BPR-MF,
WR-MF and SVD-MF, the model dimensions are increased from 8 to 128 dimensions. Finally, npmax is the
theoretical upper bound for any non-personalized ranking method.

the task of ranking on both datasets. For example on
Netﬂix a MF model with 8 dimensions optimized by
BPR-MF achieves comparable quality as a MF model
with 128 dimensions optimized by WR-MF.
To summarize, our results show the importance of op-
timizing model parameters to the right criterion. The
empirical results indicate that our BPR-Opt criterion
learned by LearnBPR outperforms the other state-
of-the-art methods for personalized ranking from im-
plicit feedback. The results are justiﬁed by the analy-
sis of the problem (section 3.2) and by the theoretical
derivation of BPR-Opt from the MLE.

6.4 Non-personalized ranking

Finally, we compare the AUC quality of our per-
sonalized ranking methods to the best possible non-
personalized ranking method. In contrast to our per-
sonalized ranking methods, a non-personalized rank-
ing method creates the same ranking > for all users.
We compute the theoretical upper-bound npmax for
any non-personalized ranking method by optimizing
2. Figure 6 shows
the ranking > on the test set Stest

that even simple personalized methods like Cosine-
kNN outperform the upper-bound npmax — and thus
also all non-personalized methods — largely.

7 Conclusion

In this paper we have presented a generic optimiza-
tion criterion and learning algorithm for personal-
ized ranking. The optimization criterion BPR-Opt
is the maximum posterior estimator that is derived
from a Bayesian analysis of the problem. For learn-
ing models with respect to BPR-Opt we have pre-
sented the generic learning algorithm LearnBPR that
is based on stochastic gradient descent with bootstrap
sampling. We have demonstrated how this generic
method can be applied to the two state-of-the-art rec-
ommender models of matrix factorization and adap-
tive kNN. In our evaluation we show empirically that
for the task of personalized ranking, models learned
by BPR outperform the same models that are opti-
mized with respect to other criteria. Our results show
that the prediction quality does not only depend on
the model but also largely on the optimization crite-

2We computed a real upper-bound but non-tight es-
timate on the AUC score. Please note that ranking by
most-popular on test is not an upper bound on AUC. But

in our experiments both AUC scores are quite similar, e.g.
on Netﬂix with most-popular on test 0.8794 vs. our upper
bound of 0.8801.

1020501000.750.800.850.90Online shopping: Rossmannnumber of dimensionsAUCllllllBPR−MFBPR−kNNWR−MFSVD−MFCosine−kNNmost popularnpmax1020501000.800.820.840.860.880.900.92Video Rental: Netflixnumber of dimensionsAUCllllllBPR−MFBPR−kNNWR−MFSVD−MFCosine−kNNmost popularnpmaxUAI 2009

RENDLE ET AL.

461

KDD ’08: Proceeding of the 14th ACM SIGKDD
international conference on Knowledge discovery
and data mining, pages 426–434, New York, NY,
USA, 2008. ACM.

[9] B. Marlin. Modeling user rating proﬁles for col-
laborative ﬁltering.
In S. Thrun, L. Saul, and
B. Sch¨olkopf, editors, Advances in Neural Infor-
mation Processing Systems 16, Cambridge, MA,
2004. MIT Press.

[10] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. M. Lukose,
M. Scholz, and Q. Yang. One-class collaborative
ﬁltering.
In IEEE International Conference on
Data Mining (ICDM 2008), pages 502–511, 2008.

[11] S. Rendle and L. Schmidt-Thieme. Online-
updating regularized kernel matrix factorization
models for large-scale recommender systems. In
RecSys ’08: Proceedings of the 2008 ACM confer-
ence on Recommender systems. ACM, 2008.

[12] J. D. M. Rennie and N. Srebro. Fast maxi-
mum margin matrix factorization for collabora-
tive prediction. In ICML ’05: Proceedings of the
22nd international conference on Machine learn-
ing, pages 713–719, New York, NY, USA, 2005.
ACM.

[13] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl.
Incremental singular value decomposition algo-
rithms for highly scalable recommender systems.
In Proceedings of the 5th International Conference
in Computers and Information Technology, 2002.

[14] L. Schmidt-Thieme. Compound classiﬁcation
models for recommender systems.
In IEEE In-
ternational Conference on Data Mining (ICDM
2005), pages 378–385, 2005.

[15] M. Weimer, A. Karatzoglou, and A. Smola. Im-
proving maximum margin matrix factorization.
Machine Learning, 72(3):263–276, 2008.

rion. Both our theoretical and empirical results indi-
cate that the BPR optimization method is the right
choice for the important task of personalized ranking.

Acknowledgements

authors

gratefully

acknowledge

par-
The
their work through the Eu-
tial co-funding of
ropean
project MyMedia
(www.mymediaproject.org) under the grant agree-
ment no. 215006. For your inquiries please contact
info@mymediaproject.org.

Commission

FP7

the

References

[1] C. Burges, T. Shaked, E. Renshaw, A. Lazier,
M. Deeds, N. Hamilton, and G. Hullender. Learn-
ing to rank using gradient descent.
In ICML
’05: Proceedings of the 22nd international con-
ference on Machine learning, pages 89–96, New
York, NY, USA, 2005. ACM Press.

[2] M. Deshpande and G. Karypis. Item-based top-n
recommendation algorithms. ACM Transactions
on Information Systems. Springer-Verlag, 22/1,
2004.

[3] A. Herschtal and B. Raskutti. Optimising area
under the roc curve using gradient descent.
In
ICML ’04: Proceedings of the twenty-ﬁrst inter-
national conference on Machine learning, page 49,
New York, NY, USA, 2004. ACM.

[4] T. Hofmann. Latent semantic models for collabo-
rative ﬁltering. ACM Trans. Inf. Syst., 22(1):89–
115, 2004.

[5] Y. Hu, Y. Koren, and C. Volinsky. Collaborative
ﬁltering for implicit feedback datasets. In IEEE
International Conference on Data Mining (ICDM
2008), pages 263–272, 2008.

[6] J. Huang, C. Guestrin, and L. Guibas. Eﬃcient
inference for distributions on permutations.
In
J. Platt, D. Koller, Y. Singer, and S. Roweis,
editors, Advances in Neural Information Process-
ing Systems 20, pages 697–704, Cambridge, MA,
2008. MIT Press.

[7] R. Kondor, A. Howard, and T. Jebara. Multi-
object tracking with representations of the sym-
metric group. In Proceedings of the Eleventh In-
ternational Conference on Artiﬁcial Intelligence
and Statistics, San Juan, Puerto Rico, March
2007.

[8] Y. Koren. Factorization meets the neighborhood:
In

a multifaceted collaborative ﬁltering model.

